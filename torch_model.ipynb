{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Lo_gvhITPlD0rgBNKKZfmAG3VOQ4y92P",
      "authorship_tag": "ABX9TyPTZLk3vTwcWzgMwb38udIM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bignamu/python-AI/blob/main/torch_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj8gqHVY6s8T"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import sys\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcPjknC14Yvj"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(1, 3)\n",
        "        self.fc2 = nn.Linear(3, 1)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(10) # 노드의 개수?\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # self.dropout = nn.Dropout(0.7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        print(x)\n",
        "        x = self.fc1(x)\n",
        "        print(x.shape)\n",
        "        print(x)\n",
        "        # x = self.batch_norm1(x)\n",
        "        # x = self.relu(x)\n",
        "        # # x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        print(x.shape)\n",
        "        print(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZANWt3864h-I"
      },
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, transforms=None):\n",
        "      self.x = [i[0] for i in data]\n",
        "      self.y = [i[1] for i in data]\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      x = [self.x[idx]]\n",
        "      y = self.y[idx]\n",
        "      x= np.array(x)\n",
        "\n",
        "\n",
        "      return x, y\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG4wc_zR4lsP",
        "outputId": "ed2e781b-a459-476f-8599-76db79745809"
      },
      "source": [
        "\n",
        "torch.manual_seed(1)\n",
        "data = [[2,0], [4,0], [6,0], [8,1], [10,1], [12,1]]\n",
        "\n",
        "train_dataset = CustomDataset(data, transforms=None)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = Net().to(device)\n",
        "\n",
        "for x, y in train_loader:\n",
        "\n",
        "    x = x.float().to(device)\n",
        "    y = y.float().to(device)\n",
        "    print(x)\n",
        "    print('------------------'*5)\n",
        "    outputs = model(x)\n",
        "    print('------------------'*5)\n",
        "    print(outputs)\n",
        "    outputs = outputs.detach().numpy()\n",
        "    print(outputs)\n",
        "    print(y)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.]])\n",
            "------------------------------------------------------------------------------------------\n",
            "torch.Size([1, 1])\n",
            "tensor([[2.]])\n",
            "torch.Size([1, 3])\n",
            "tensor([[ 1.4999, -1.8242,  0.2120]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([1, 1])\n",
            "tensor([[0.]], grad_fn=<ReluBackward1>)\n",
            "------------------------------------------------------------------------------------------\n",
            "tensor([[0.]], grad_fn=<ReluBackward1>)\n",
            "[[0.]]\n",
            "tensor([0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNk3SmPK4m0u"
      },
      "source": [
        "# Pytorch Class 구조"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvNd4QHRphSn"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(1, 1)\n",
        "        self.fc2 = nn.Linear(3, 1)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(3)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.sig = nn.Sigmoid() # 활성화 함수\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        # x = self.batch_norm1(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.dropout(x)\n",
        "        # x = self.fc2(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.sig(x)\n",
        "         #H(X)식에 입력X 로부터 예측된 y를 얻는 것을 forward 연산이라고 함\n",
        "        return x\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transforms=None):\n",
        "        self.x = [i[0] for i in data]\n",
        "        self.y = [i[1] for i in data]\n",
        "         # 데이터셋의 전처리를 해주는 부분\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "        # 데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = [self.x[idx]]\n",
        "        y = self.y[idx]\n",
        "        x = np.array(x)\n",
        "        y = np.array(y)\n",
        "        #  데이터셋에서 특정 샘플을 가져오는 함수 ? forward\n",
        "\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYMFgErQ-4Z9",
        "outputId": "7397f1d3-3710-445a-ebc0-92a4a938e127"
      },
      "source": [
        "!cd /content/drive/MyDrive/Colab Notebooks/Pytorch\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: too many arguments\n",
            "/content\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "1eSWCYYmpoIP",
        "outputId": "1c653b49-4031-44a1-a58b-15082ea5ad60"
      },
      "source": [
        "data = [[2, 4], [4, 8], [6, 12], [8, 16], [10, 20], [12, 24]]\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# 커스텀 데이터 로드 과정\n",
        "train_dataset = CustomDataset(data, transforms=None)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
        "# 미니 배치 학습을 하게되면 미니 배치만큼만 가져가서 미니 배치에 대한 대한 비용(cost)를 계산하고, gradient descent을 수행합니다. \n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = Net().to(device)\n",
        "criterion = nn.MSELoss() # 비용함수 선언 MSE의 최솟값이 훈련 데이터를 가장 잘 나타내는 직선을 나타낼것\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "optimizer =torch.optim.SGD(model.parameters() , lr=  0.001) \n",
        "# 최소의 W b를 찾아내는 과정 optimizer를 SGD를 사용했다는 뜻\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.1) \n",
        "#일정한 Step 마다 learning rate에 gamma를 곱해주는 방식\n",
        "epoch = 1000\n",
        "total_loss = 0\n",
        "for i in range(epoch):\n",
        "    for x, y in train_loader:\n",
        "        x = x.float().to(device)\n",
        "        y = y.float().to(device)\n",
        "        # print('x,y', x,y)\n",
        "        # print(x, y)\n",
        "        outputs = model(x)\n",
        "        # print('outputs ',outputs)\n",
        "        loss = criterion(outputs, y)\n",
        "        optimizer.zero_grad()  # 기울기 초기화 //가중치와 편향의 초기화\n",
        "        loss.backward()  # 가중치와 편향에 대해 기울기 계산\n",
        "        total_loss += loss.item() # 텐서안에 있는 값을 나타냄\n",
        "        outputs = outputs.detach().numpy()\n",
        "        # print('outputs ',outputs)\n",
        "        y = y.numpy()\n",
        "        # sys.exit()\n",
        "        # print(outputs)\n",
        "        # print(y)\n",
        "    if i == 999:\n",
        "        torch.save(model.state_dict(), f'weight/model_last.pth')\n",
        "    print(f\"epoch -> {i}      loss -- > \", total_loss / len(train_loader) if epoch i % 10 == 0)\n",
        "    optimizer.step()\n",
        "    total_loss = 0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5752e1b1c8cc>\"\u001b[0;36m, line \u001b[0;32m41\u001b[0m\n\u001b[0;31m    print(f\"epoch -> {i}      loss -- > \", total_loss / len(train_loader) if epoch i % 10 == 0)\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbno3JhJydEA",
        "outputId": "856b92ea-65bc-40c4-a767-66127e588f55"
      },
      "source": [
        "\n",
        "model.eval() # W b 고정하겠다\n",
        "model.load_state_dict(torch.load('weight/model_last.pth'))\n",
        "test_data = [[1, 2],[3, 6],[5, 10]]\n",
        "test_dataset = CustomDataset(test_data, transforms=None)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "for x, y in test_loader:\n",
        "    x = x.float().to(device)\n",
        "    y = y.long().to(device)\n",
        "    # print('x, y : ', x, y)\n",
        "    outputs = model(x)\n",
        "    print('x, y, outputs : ',x,y,outputs)\n",
        "\n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x, y, outputs :  tensor([[1.]]) tensor([2]) tensor([[3.8605]], grad_fn=<AddmmBackward>)\n",
            "x, y, outputs :  tensor([[3.]]) tensor([6]) tensor([[6.6733]], grad_fn=<AddmmBackward>)\n",
            "x, y, outputs :  tensor([[5.]]) tensor([10]) tensor([[9.4862]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
              "  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",
              "  (batch_norm1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (dropout): Dropout(p=0.7, inplace=False)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoKBsqm_DNGI"
      },
      "source": [
        "# Pytorch Iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6OsyHqmYZme"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "import torch.nn.functional as F\n",
        "import torch.optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVlb5g9AYnpX"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(4, 3)\n",
        "        # self.fc2 = nn.Linear(3, 1)\n",
        "        # self.batch_norm1 = nn.BatchNorm1d(3)\n",
        "        # self.relu = nn.ReLU(inplace=True)\n",
        "        self.sig = nn.Sigmoid() # 활성화 함수\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        # x = self.batch_norm1(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.dropout(x)\n",
        "        # x = self.fc2(x)\n",
        "        # x = self.relu(x)\n",
        "        x = self.sig(x) * x\n",
        "        #H(X)식에 입력X 로부터 예측된 y를 얻는 것을 forward 연산이라고 함\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLPWsFBWlPgH"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X,y, transforms=None):\n",
        "        self.x = [i for i in X]\n",
        "        self.y = [i for i in y]\n",
        "         # 데이터셋의 전처리를 해주는 부분\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "        # 데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x[idx]\n",
        "        y = self.y[idx]\n",
        "        x = np.array(x)\n",
        "        y = np.array(y)\n",
        "\n",
        "        #  데이터셋에서 특정 샘플을 가져오는 함수 ? forward\n",
        "\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KimcQsrvfl9q"
      },
      "source": [
        "iris_dataset = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm_82JuSf3nQ",
        "outputId": "61cded81-0269-4b80-ee7b-b2be4d62465c"
      },
      "source": [
        "print(iris_dataset.keys(), type(iris_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']) <class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mx95oQpf33g",
        "outputId": "8891d37a-971f-4777-d656-9660fcae7f2d"
      },
      "source": [
        "print(iris_dataset['data'].shape, iris_dataset['target_names'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4) (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnZ86TmRgI2w"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    iris_dataset['data'],\n",
        "                                                    iris_dataset['target'],\n",
        "                                                    stratify=iris_dataset['target'],\n",
        "                                                    random_state=0\n",
        "                                                    )\n",
        "# stratify 분류 라벨 샘플 분산시키기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nckmdFvUlW2I"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "train_dataset = CustomDataset(X_train,y_train, transforms=None)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RqZ59BwgdU4"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss() # 비용함수\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.01) # gradient descent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqTYiSBug4Wm",
        "outputId": "ed95d163-ab72-48b1-f2e5-97ef7c428778"
      },
      "source": [
        "epoch = 100\n",
        "total_loss = 0\n",
        "print(len(train_loader))\n",
        "print(train_loader.dataset.y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "112\n",
            "[1, 0, 0, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkNFFHexh9eW"
      },
      "source": [
        "for i in range(epoch):\n",
        "  total_loss = 0\n",
        "  #print(i)\n",
        "  for X_train, y_train in train_loader:\n",
        "    #print(X_train,y_train)\n",
        "    X_train = X_train.float().to(device) # 차원 분별필요\n",
        "    y_train = y_train.long().to(device) #long\n",
        "\n",
        "    outputs = model(X_train)\n",
        "    #print(outputs,X_train,y_train)\n",
        "    loss = criterion(outputs, y_train) # outputs.view_as...\n",
        "    optimizer.zero_grad()  # 기울기 초기화 //가중치와 편향의 초기화\n",
        "    loss.backward()  # 가중치와 편향에 대해 기울기 계산\n",
        "    total_loss += loss.item() # 텐서안에 있는 값을 나타냄\n",
        "    outputs = outputs.detach().numpy()\n",
        "    # print('outputs ',outputs)\n",
        "    y_train = y_train.numpy()\n",
        "    optimizer.step()\n",
        "    total_loss = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC-I_S1gijxL"
      },
      "source": [
        "\n",
        "model.eval() # W b 고정하겠다\n",
        "# model.load_state_dict(torch.load('weight/model_last.pth'))\n",
        "test_dataset = CustomDataset(X_test,y_test, transforms=None)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "for x, y in test_loader:\n",
        "    x = x.float().to(device)\n",
        "    y = y.long().to(device)\n",
        "    # print('x, y : ', x, y)\n",
        "    outputs = model(x)\n",
        "    _, predicted = torch.max(outputs,0)\n",
        "    #print('x, y, outputs : ',x,y,predicted)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}