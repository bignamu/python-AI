{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ba541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24edc346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11f86a3d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 실습하고 있는 파이썬 코드 재실행 해도 다음에도 같은 결과가 나오도록 랜덤 시드 설정 \n",
    "torch.manual_seed(7711)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56778b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_trian >>  torch.Size([3, 1])\n",
      "y_train >>  torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# 실습을 위한 기본 세팅 작업 \n",
    "# 훈련 데이터 x_train, y_train \n",
    "x_train = torch.FloatTensor(([1], [2], [3]))\n",
    "y_train = torch.FloatTensor(([2], [4], [7]))\n",
    "\n",
    "# x_train shape show \n",
    "print(\"x_trian >> \", x_train.shape) # shape or size()\n",
    "print(\"y_train >> \", y_train.size())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de0ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 w  tensor([0.], requires_grad=True)\n",
      "편향 b  tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 편향의 초기화 \n",
    "# 가중치 0 으로 초기화하고 이값을 출력 편향 b도 0으로 초기화 \n",
    "# requires_grad = True -> 학습을 통해서 계속 값이 변경되는 변수입니다. \n",
    "w = torch.zeros(1, requires_grad = True)\n",
    "print(\"가중치 w \", w)\n",
    "\n",
    "b = torch.zeros(1,requires_grad = True)\n",
    "print(\"편향 b \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ad47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 : tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 가설 선언 \n",
    "# 파이토치 코드 상으로 직선의 방정식에 해당되는 가설을 선언 \n",
    "hypothersis = x_train * w + b\n",
    "print(\"가설 :\", hypothersis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f91bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Loss function 선언 \n",
    "loss = torch.mean((hypothersis - y_train) ** 2 )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc55a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법 구현 \n",
    "# input w b rk sgd 입력이 되어야합니다. \n",
    "optimizer = optim.SGD([w, b], lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db96f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기울기 0 초기화 \n",
    "optimizer.zero_grad()\n",
    "\n",
    "# loss fn 미분 하여 기울기 계산 \n",
    "loss.backward()\n",
    "\n",
    "# w 와 b 값을 업데이트 \n",
    "optimizer.step()\n",
    "\n",
    "# 학습을 진행 \n",
    "epoch_num = 3000 # 원하는 만큼 경사 하강법을 반복 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087b0f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/3000 w : 0.391, b :0.163 loss : 18.256254\n",
      "Epoch  100/3000 w : 1.991, b :0.491 loss : 0.248801\n",
      "Epoch  200/3000 w : 2.100, b :0.244 loss : 0.174969\n",
      "Epoch  300/3000 w : 2.185, b :0.049 loss : 0.129346\n",
      "Epoch  400/3000 w : 2.253, b :-0.104 loss : 0.101154\n",
      "Epoch  500/3000 w : 2.306, b :-0.225 loss : 0.083732\n",
      "Epoch  600/3000 w : 2.347, b :-0.319 loss : 0.072967\n",
      "Epoch  700/3000 w : 2.380, b :-0.393 loss : 0.066315\n",
      "Epoch  800/3000 w : 2.406, b :-0.452 loss : 0.062204\n",
      "Epoch  900/3000 w : 2.426, b :-0.498 loss : 0.059664\n",
      "Epoch 1000/3000 w : 2.442, b :-0.534 loss : 0.058094\n",
      "Epoch 1100/3000 w : 2.454, b :-0.562 loss : 0.057124\n",
      "Epoch 1200/3000 w : 2.464, b :-0.585 loss : 0.056525\n",
      "Epoch 1300/3000 w : 2.472, b :-0.602 loss : 0.056155\n",
      "Epoch 1400/3000 w : 2.478, b :-0.616 loss : 0.055926\n",
      "Epoch 1500/3000 w : 2.482, b :-0.627 loss : 0.055784\n",
      "Epoch 1600/3000 w : 2.486, b :-0.635 loss : 0.055697\n",
      "Epoch 1700/3000 w : 2.489, b :-0.642 loss : 0.055643\n",
      "Epoch 1800/3000 w : 2.491, b :-0.647 loss : 0.055610\n",
      "Epoch 1900/3000 w : 2.493, b :-0.651 loss : 0.055589\n",
      "Epoch 2000/3000 w : 2.495, b :-0.655 loss : 0.055576\n",
      "Epoch 2100/3000 w : 2.496, b :-0.657 loss : 0.055568\n",
      "Epoch 2200/3000 w : 2.497, b :-0.659 loss : 0.055563\n",
      "Epoch 2300/3000 w : 2.497, b :-0.661 loss : 0.055560\n",
      "Epoch 2400/3000 w : 2.498, b :-0.662 loss : 0.055559\n",
      "Epoch 2500/3000 w : 2.498, b :-0.663 loss : 0.055557\n",
      "Epoch 2600/3000 w : 2.499, b :-0.664 loss : 0.055557\n",
      "Epoch 2700/3000 w : 2.499, b :-0.664 loss : 0.055556\n",
      "Epoch 2800/3000 w : 2.499, b :-0.665 loss : 0.055556\n",
      "Epoch 2900/3000 w : 2.499, b :-0.665 loss : 0.055556\n",
      "Epoch 3000/3000 w : 2.500, b :-0.666 loss : 0.055556\n"
     ]
    }
   ],
   "source": [
    "# train mode\n",
    "# epoch -> 전체훈련 데이터가 학습에 한번 사용되는 주기를 말합니다.\n",
    "for epoch in range(epoch_num + 1):\n",
    "    \n",
    "    # 가설 계산 \n",
    "    hypothersis = x_train * w + b \n",
    "    \n",
    "    # loss 계산 \n",
    "    loss = torch.mean((hypothersis - y_train) ** 2)\n",
    "    \n",
    "    # loss \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번 마다 print \n",
    "    if epoch % 100 == 0 :\n",
    "        print(\"Epoch {:4d}/{} w : {:.3f}, b :{:.3f} loss : {:.6f}\"\n",
    "              .format(epoch, epoch_num, w.item(), b.item(), loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b21bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
